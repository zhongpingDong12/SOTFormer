{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "463fc67e-9fed-44de-941f-0591c15f5863",
   "metadata": {},
   "source": [
    "### Paths & Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ab10f06-841f-489b-b608-dca3d793918e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paths set. Edit above if needed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "DATA_DIR   = \"/apps/data/share/LaSOT14_Dataset\"               \n",
    "TRAIN_JSON = \"/apps/data/share/LaSOT14_Dataset/annotations/train/train.json\"\n",
    "TEST_JSON  = \"/apps/data/share/LaSOT14_Dataset/annotations/test/test.json\"\n",
    "VAL_JSON  = \"/apps/data/share/LaSOT14_Dataset/annotations/val/val.json\"\n",
    "LOCAL_DETR = \"/apps/data/share/models/deformable_detr_coco\"\n",
    "REPO_OSTRACK     = \"/apps/data/share/repos/OSTrack\"\n",
    "REPO_TRACKFORMER = \"/apps/data/share/repos/TrackFormer\"\n",
    "REPO_MOTRV2      = \"/apps/data/share/repos/MOTRv2\"\n",
    "os.environ[\"LOCAL_DEFORMABLE_DETR_PATH\"] = LOCAL_DETR\n",
    "\n",
    "print(\"Paths set. Edit above if needed.\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a208ee-05d4-47c3-a745-acddc84b4853",
   "metadata": {},
   "source": [
    "### Dependencies checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0b0ed10-9628-4dc2-aff4-76243c286055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 2.9.0+cu128\n",
      "torchvision: 0.24.0+cu128\n",
      "transformers: 4.57.1\n",
      "opencv: 4.12.0\n"
     ]
    }
   ],
   "source": [
    "import torch, torchvision, transformers, cv2\n",
    "print(\"torch:\", torch.__version__)          \n",
    "print(\"torchvision:\", torchvision.__version__)\n",
    "print(\"transformers:\", transformers.__version__)\n",
    "print(\"opencv:\", cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cfa0785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PYTORCH_ALLOC_CONF=expandable_segments:True,max_split_size_mb:128,garbage_collection_threshold:0.8\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Reset allocator envs (remove old lowercase 'true') \n",
    "unset PYTORCH_CUDA_ALLOC_CONF\n",
    "unset PYTORCH_ALLOC_CONF\n",
    "\n",
    "# Good allocator config (booleans must be 'True'/'False')  \n",
    "export PYTORCH_ALLOC_CONF='expandable_segments:True,max_split_size_mb:128,garbage_collection_threshold:0.8'\n",
    "\n",
    "# Optional NCCL safety  \n",
    "export TORCH_NCCL_BLOCKING_WAIT=1\n",
    "export TORCH_NCCL_ASYNC_ERROR_HANDLING=1\n",
    "export NCCL_IB_DISABLE=1\n",
    "\n",
    "# Show what will be inherited  \n",
    "echo \"PYTORCH_ALLOC_CONF=$PYTORCH_ALLOC_CONF\"\n",
    "\n",
    "# Kill your own leftovers only  \n",
    "pkill -f \"torchrun .*Project2_SOFT/train.py\"  || true\n",
    "pkill -f \"python .*Project2_SOFT/train.py\"    || true\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7a5e96-d6c1-4a79-a3aa-206c0b5cd916",
   "metadata": {},
   "source": [
    "### Train our model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb645bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "set -e\n",
    "\n",
    "CUDA_VISIBLE_DEVICES=2,3,4,5,6,7 \\\n",
    "OMP_NUM_THREADS=1 \\\n",
    "TORCH_NCCL_BLOCKING_WAIT=1 \\\n",
    "TORCH_NCCL_ASYNC_ERROR_HANDLING=1 \\\n",
    "NCCL_IB_DISABLE=1 \\\n",
    "MASTER_ADDR=127.0.0.1 \\\n",
    "MASTER_PORT=29509 \\\n",
    "PYTORCH_CUDA_ALLOC_CONF='expandable_segments:True,max_split_size_mb:128,garbage_collection_threshold:0.8' \\\n",
    "torchrun --standalone --nproc_per_node=6 train_improved.py \\\n",
    "  --data_dir   /apps/data/share/LaSOT14_Dataset \\\n",
    "  --train_json /apps/data/share/LaSOT14_Dataset/annotations/train/train.json \\\n",
    "  --val_json   /apps/data/share/LaSOT14_Dataset/annotations/val/val.json \\\n",
    "  --output_dir ../ckpts/run_improved_v1 \\\n",
    "  --epochs 100 \\\n",
    "  --batch_size 1 \\\n",
    "  --segment_len 24 \\\n",
    "  --tail_len 24 \\\n",
    "  --variant temporal_primed \\\n",
    "  --k_burnin 3 \\\n",
    "  --prime_p_start 1.0 \\\n",
    "  --prime_p_end 0.7 \\\n",
    "  --prime_decay_epochs 60 \\\n",
    "  --lr_heads 2e-4 \\\n",
    "  --lr_backbone 2e-5 \\\n",
    "  --weight_decay 1e-4 \\\n",
    "  --short_side 768 \\\n",
    "  --max_side 1024 \\\n",
    "  --num_queries 300 \\\n",
    "  --early_stop_patience 15 \\\n",
    "  --plateau_patience 5 \\\n",
    "  --plateau_factor 0.5 \\\n",
    "  --clip_grad_norm 0.5 \\\n",
    "  --gt_fmt auto \\\n",
    "  --diag_norm 0.005 \\\n",
    "  --p20 20 \\\n",
    "  --find_unused \\\n",
    "  --augment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7221bc-d8b6-48bd-9e6f-19d9e132cbf8",
   "metadata": {},
   "source": [
    "### Ablations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ce33edc-750b-4afe-b34e-f363faf86d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Frame-only (no temporal, no priming, no anchor) \n",
    "!torchrun --standalone --nproc_per_node=8 ../train.py \\\n",
    "  --data_dir \"{DATA_DIR}\" --train_json \"{TRAIN_JSON}\" \\\n",
    "  --output_dir ../ckpts/frame_only --epochs 10 --batch_size 8 \\\n",
    "  --segment_len 30 --future_len 10 --variant frame_only\n",
    "\n",
    "# 2) + Temporal (no priming, no anchor) \n",
    "!torchrun --standalone --nproc_per_node=8 ../train.py \\\n",
    "  --data_dir \"{DATA_DIR}\" --train_json \"{TRAIN_JSON}\" \\\n",
    "  --output_dir ../ckpts/temporal --epochs 10 --batch_size 8 \\\n",
    "  --segment_len 30 --future_len 10 --variant temporal\n",
    "\n",
    "# 3) + GT-Primed (still no anchor) \n",
    "!torchrun --standalone --nproc_per_node=8 ../train.py \\\n",
    "  --data_dir \"{DATA_DIR}\" --train_json \"{TRAIN_JSON}\" \\\n",
    "  --output_dir ../ckpts/temporal_primed --epochs 10 --batch_size 8 \\\n",
    "  --segment_len 30 --future_len 10 --variant temporal_primed\n",
    "\n",
    "# 4) + Burn-in Anchor Loss \n",
    "!torchrun --standalone --nproc_per_node=8 ../train.py \\\n",
    "  --data_dir \"{DATA_DIR}\" --train_json \"{TRAIN_JSON}\" \\\n",
    "  --output_dir ../ckpts/temporal_primed_anchor --epochs 10 --batch_size 8 \\\n",
    "  --segment_len 30 --future_len 10 --variant temporal_primed_anchor --w_anchor 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310a35ce-8621-4ed1-80ec-bddbca1275f6",
   "metadata": {},
   "source": [
    "### Inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d777d009-ebf0-4099-8a23-a169935243d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: during inference, we disable priming; choose \"temporal\" or \"frame_only\" path \n",
    "!torchrun --standalone --nproc_per_node=8 ../test.py \\\n",
    "  --data_dir \"{DATA_DIR}\" --test_json \"{TEST_JSON}\" \\\n",
    "  --checkpoint ../ckpts/full/checkpoint_final.pth \\\n",
    "  --output_dir ../results/full --variant temporal\n",
    "\n",
    "# Frame-only\n",
    "!torchrun --standalone --nproc_per_node=8 ../test.py \\\n",
    "  --data_dir \"{DATA_DIR}\" --test_json \"{TEST_JSON}\" \\\n",
    "  --checkpoint ../ckpts/frame_only/checkpoint_final.pth \\\n",
    "  --output_dir ../results/frame_only --variant frame_only\n",
    "\n",
    "# Temporal\n",
    "!torchrun --standalone --nproc_per_node=8 ../test.py \\\n",
    "  --data_dir \"{DATA_DIR}\" --test_json \"{TEST_JSON}\" \\\n",
    "  --checkpoint ../ckpts/temporal/checkpoint_final.pth \\\n",
    "  --output_dir ../results/temporal --variant temporal\n",
    "\n",
    "# Temporal + Primed\n",
    "!torchrun --standalone --nproc_per_node=8 ../test.py \\\n",
    "  --data_dir \"{DATA_DIR}\" --test_json \"{TEST_JSON}\" \\\n",
    "  --checkpoint ../ckpts/temporal_primed/checkpoint_final.pth \\\n",
    "  --output_dir ../results/temporal_primed --variant temporal\n",
    "\n",
    "# Temporal + Primed + Anchor\n",
    "!torchrun --standalone --nproc_per_node=8 ../test.py \\\n",
    "  --data_dir \"{DATA_DIR}\" --test_json \"{TEST_JSON}\" \\\n",
    "  --checkpoint ../ckpts/temporal_primed_anchor/checkpoint_final.pth \\\n",
    "  --output_dir ../results/temporal_primed_anchor --variant temporal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8db258f-0e0e-4a8f-80c0-be7534eb7c99",
   "metadata": {},
   "source": [
    "### Evaluation (AUC / Precision / ADE / FDE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf088ae8-1027-43fd-bee7-1039960b86d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate five result folders; print metrics for table copy \n",
    "!python ../eval_metrics.py --data_dir \"{DATA_DIR}\" --test_json \"{TEST_JSON}\" --result_dir ../results/full\n",
    "!python ../eval_metrics.py --data_dir \"{DATA_DIR}\" --test_json \"{TEST_JSON}\" --result_dir ../results/frame_only\n",
    "!python ../eval_metrics.py --data_dir \"{DATA_DIR}\" --test_json \"{TEST_JSON}\" --result_dir ../results/temporal\n",
    "!python ../eval_metrics.py --data_dir \"{DATA_DIR}\" --test_json \"{TEST_JSON}\" --result_dir ../results/temporal_primed\n",
    "!python ../eval_metrics.py --data_dir \"{DATA_DIR}\" --test_json \"{TEST_JSON}\" --result_dir ../results/temporal_primed_anchor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284d5001-c642-40c9-97ff-57ef2f9ea038",
   "metadata": {},
   "source": [
    "### Visualize one sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5ded4f-80c3-4dc2-9841-8b85cce07e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick one test sequence name from your LaSOT split \n",
    "SEQ = \"airplane-1\"  # change accordingly \n",
    "\n",
    "# Draw Pred (red) and GT (green, if available) and export MP4 \n",
    "!python ../visualize_results.py --sequence \"{SEQ}\" --data_dir \"{DATA_DIR}\" \\\n",
    "  --result_dir ../results/full --output_video ../vis_{SEQ}.mp4 --show_gt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9708cdbd-0774-41e0-82d1-237967614cc3",
   "metadata": {},
   "source": [
    "### External baselines (OSTrack / TrackFormer / MOTRv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2ec2ad-345f-43f3-b46b-c8a495b7de9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure repos are cloned and deps installed per each README \n",
    "# Each run: train -> infer -> export <seq>.txt into work_dir/results \n",
    "# OSTrack\n",
    "!python ../baselines_runner.py --model ostrack --repo_root \"{REPO_OSTRACK}\" \\\n",
    "  --data_dir \"{DATA_DIR}\" --train_json \"{TRAIN_JSON}\" --test_json \"{TEST_JSON}\" \\\n",
    "  --work_dir ../work/ostrack --gpus 8\n",
    "!python ../eval_metrics.py --data_dir \"{DATA_DIR}\" --test_json \"{TEST_JSON}\" --result_dir ../work/ostrack/results\n",
    "\n",
    "# TrackFormer\n",
    "!python ../baselines_runner.py --model trackformer --repo_root \"{REPO_TRACKFORMER}\" \\\n",
    "  --data_dir \"{DATA_DIR}\" --train_json \"{TRAIN_JSON}\" --test_json \"{TEST_JSON}\" \\\n",
    "  --work_dir ../work/trackformer --gpus 8\n",
    "!python ../eval_metrics.py --data_dir \"{DATA_DIR}\" --test_json \"{TEST_JSON}\" --result_dir ../work/trackformer/results\n",
    "\n",
    "# MOTRv2\n",
    "!python ../baselines_runner.py --model motrv2 --repo_root \"{REPO_MOTRV2}\" \\\n",
    "  --data_dir \"{DATA_DIR}\" --train_json \"{TRAIN_JSON}\" --test_json \"{TEST_JSON}\" \\\n",
    "  --work_dir ../work/motrv2 --gpus 8\n",
    "!python ../eval_metrics.py --data_dir \"{DATA_DIR}\" --test_json \"{TEST_JSON}\" --result_dir ../work/motrv2/results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae33114-b376-4b1c-b121-4ba62cc4536b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
